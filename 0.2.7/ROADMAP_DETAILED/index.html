
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Unified Python toolkit for visual document processing">
      
      
      
        <link rel="canonical" href="https://adithya-s-k.github.io/Omnidocs/0.2.7/ROADMAP_DETAILED/">
      
      
      
      
        
      
      
      <link rel="icon" href="../assets/logo.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.1">
    
    
      
        <title>OmniDocs Development Roadmap - OmniDocs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.484c7ddc.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="light-blue">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#omnidocs-development-roadmap" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="OmniDocs" class="md-header__button md-logo" aria-label="OmniDocs" data-md-component="logo">
      
  <img src="../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            OmniDocs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              OmniDocs Development Roadmap
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/adithya-s-k/OmniDocs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    adithya-s-k/OmniDocs
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href=".." class="md-tabs__link">
          
  
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../usage/" class="md-tabs__link">
        
  
  
    
  
  Usage

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../reference/batch/" class="md-tabs__link">
          
  
  
    
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../contributing/" class="md-tabs__link">
        
  
  
    
  
  Contributing

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../ROADMAP/" class="md-tabs__link">
        
  
  
    
  
  Roadmap

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="OmniDocs" class="md-nav__button md-logo" aria-label="OmniDocs" data-md-component="logo">
      
  <img src="../assets/logo.png" alt="logo">

    </a>
    OmniDocs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/adithya-s-k/OmniDocs" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    adithya-s-k/OmniDocs
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href=".." class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Home
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Installation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Concepts
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../usage/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Usage
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Usage
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../usage/tasks/text-extraction/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Text Extraction
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            
  
    Text Extraction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/mineruvl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MinerU VL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/qwen/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Qwen
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/dotsocr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    DotsOCR
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/nanonets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Nanonets OCR2
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../usage/tasks/layout-analysis/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Layout Analysis
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_2" id="__nav_2_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Layout Analysis
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/mineruvl/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MinerU VL
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/doclayout-yolo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    DocLayoutYOLO
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/rtdetr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    RT-DETR
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../usage/tasks/ocr/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    OCR
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    OCR
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/tesseract/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tesseract
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/easyocr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    EasyOCR
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/paddleocr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PaddleOCR
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../usage/tasks/table-extraction/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Table Extraction
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Table Extraction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/models/tableformer/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    TableFormer
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/tasks/reading-order/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Reading Order
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/batch-processing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Batch Processing
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../guides/model-cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Model Cache
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/deployment/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Deployment
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    API Reference
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/batch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Batch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cache
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/document/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Document
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Tasks
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Tasks
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_2" >
        
          
          <label class="md-nav__link" for="__nav_3_4_2" id="__nav_3_4_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Layout Extraction
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_2">
            <span class="md-nav__icon md-icon"></span>
            
  
    Layout Extraction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Base
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/doc_layout_yolo/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Doc Layout YOLO
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_2_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4_2_4" id="__nav_3_4_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Mineruvl
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_2_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Mineruvl
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/mineruvl/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/mineruvl/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/mineruvl/detector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Detector
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/mineruvl/mlx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/mineruvl/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/mineruvl/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_2_6" >
        
          
          <label class="md-nav__link" for="__nav_3_4_2_6" id="__nav_3_4_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Qwen
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_2_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Qwen
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/qwen/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/qwen/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/qwen/detector/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Detector
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/qwen/mlx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/qwen/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/qwen/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/layout_extraction/rtdetr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Rtdetr
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_3" >
        
          
          <label class="md-nav__link" for="__nav_3_4_3" id="__nav_3_4_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    OCR Extraction
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    OCR Extraction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/ocr_extraction/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/ocr_extraction/base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Base
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/ocr_extraction/easyocr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    EasyOCR
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/ocr_extraction/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/ocr_extraction/paddleocr/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PaddleOCR
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/ocr_extraction/tesseract/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Tesseract
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4_4" id="__nav_3_4_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Reading Order
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Reading Order
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/reading_order/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/reading_order/base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Base
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/reading_order/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_4_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4_4_4" id="__nav_3_4_4_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Rule Based
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_4_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Rule Based
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/reading_order/rule_based/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/reading_order/rule_based/predictor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Predictor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_5" >
        
          
          <label class="md-nav__link" for="__nav_3_4_5" id="__nav_3_4_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Table Extraction
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Table Extraction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/table_extraction/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/table_extraction/base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Base
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/table_extraction/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_5_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4_5_4" id="__nav_3_4_5_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Tableformer
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_5_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Tableformer
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/table_extraction/tableformer/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/table_extraction/tableformer/config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Config
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/table_extraction/tableformer/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_6" >
        
          
          <label class="md-nav__link" for="__nav_3_4_6" id="__nav_3_4_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Text Extraction
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6">
            <span class="md-nav__icon md-icon"></span>
            
  
    Text Extraction
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/base/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Base
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_6_3" >
        
          
          <label class="md-nav__link" for="__nav_3_4_6_3" id="__nav_3_4_6_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Dots OCR
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_6_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6_3">
            <span class="md-nav__icon md-icon"></span>
            
  
    Dots OCR
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/dots_ocr/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/dots_ocr/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/dots_ocr/extractor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extractor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/dots_ocr/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/dots_ocr/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_6_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4_6_4" id="__nav_3_4_6_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Granitedocling
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_6_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Granitedocling
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/granitedocling/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/granitedocling/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/granitedocling/extractor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extractor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/granitedocling/mlx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/granitedocling/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/granitedocling/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_6_5" >
        
          
          <label class="md-nav__link" for="__nav_3_4_6_5" id="__nav_3_4_6_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Mineruvl
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_6_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Mineruvl
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/extractor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extractor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/mlx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Utils
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/mineruvl/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_6_7" >
        
          
          <label class="md-nav__link" for="__nav_3_4_6_7" id="__nav_3_4_6_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Nanonets
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_6_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6_7">
            <span class="md-nav__icon md-icon"></span>
            
  
    Nanonets
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/nanonets/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/nanonets/extractor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extractor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/nanonets/mlx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/nanonets/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/nanonets/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4_6_8" >
        
          
          <label class="md-nav__link" for="__nav_3_4_6_8" id="__nav_3_4_6_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Qwen
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_4_6_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4_6_8">
            <span class="md-nav__icon md-icon"></span>
            
  
    Qwen
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/qwen/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/qwen/api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/qwen/extractor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Extractor
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/qwen/mlx/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    MLX
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/qwen/pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    PyTorch
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/tasks/text_extraction/qwen/vllm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    VLLM
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    
  
    Utils
  

    
  </span>
  
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            
  
    Utils
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/utils/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Overview
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/utils/aggregation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Aggregation
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/utils/cache/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Cache
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../contributing/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    
  
    Contributing
  

    
  </span>
  
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            
  
    Contributing
  

          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/workflow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Development Workflow
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Testing Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/adding-models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Adding Models
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/style-guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Style Guide
  

    
  </span>
  
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../ROADMAP/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Roadmap
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#target-model-support" class="md-nav__link">
    <span class="md-ellipsis">
      
         Target Model Support
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quick-reference-model-capabilities-backend-support" class="md-nav__link">
    <span class="md-ellipsis">
      
         Quick Reference: Model Capabilities &amp; Backend Support
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Quick Reference: Model Capabilities &amp; Backend Support">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#comprehensive-model-comparison-table" class="md-nav__link">
    <span class="md-ellipsis">
      
        Comprehensive Model Comparison Table
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#backend-details" class="md-nav__link">
    <span class="md-ellipsis">
      
        Backend Details
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Backend Details">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pytorch-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        PyTorch Support
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-support-high-throughput-production" class="md-nav__link">
    <span class="md-ellipsis">
      
        VLLM Support (High-Throughput Production)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mlx-support-apple-silicon-m1m2m3" class="md-nav__link">
    <span class="md-ellipsis">
      
        MLX Support (Apple Silicon M1/M2/M3+)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#openai-compatible-api-providers" class="md-nav__link">
    <span class="md-ellipsis">
      
        OpenAI-Compatible API Providers
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#task-capability-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task Capability Matrix
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-overview-by-task-capability" class="md-nav__link">
    <span class="md-ellipsis">
      
        Model Overview by Task Capability
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Overview by Task Capability">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#task-categories" class="md-nav__link">
    <span class="md-ellipsis">
      
        Task Categories
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#latest-models-january-2026" class="md-nav__link">
    <span class="md-ellipsis">
      
         Latest Models (January 2026)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Latest Models (January 2026)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#deepseek-ocr-2" class="md-nav__link">
    <span class="md-ellipsis">
      
        DeepSeek-OCR-2
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lightonocr-2-1b" class="md-nav__link">
    <span class="md-ellipsis">
      
        LightOnOCR-2-1B
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ocrflux-3b" class="md-nav__link">
    <span class="md-ellipsis">
      
        OCRFlux-3B
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#core-models-by-size-release-date" class="md-nav__link">
    <span class="md-ellipsis">
      
         Core Models (By Size &amp; Release Date)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Core Models (By Size &amp; Release Date)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ultra-compact-models-1b-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ultra-Compact Models (&lt;1B Parameters)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Ultra-Compact Models (&lt;1B Parameters)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ibm-granite-docling-258m" class="md-nav__link">
    <span class="md-ellipsis">
      
        IBM Granite-Docling-258M
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-stepfun-ai-got-ocr20" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. stepfun-ai GOT-OCR2.0
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#compact-models-1-2b-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Compact Models (1-2B Parameters)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compact Models (1-2B Parameters)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3-rednote-hilab-dotsocr" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. rednote-hilab dots.ocr
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-paddlepaddle-paddleocr-vl" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. PaddlePaddle PaddleOCR-VL
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-lighton-ai-lightonocr-series" class="md-nav__link">
    <span class="md-ellipsis">
      
        5. LightOn AI LightOnOCR Series
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-opendatalab-mineru25" class="md-nav__link">
    <span class="md-ellipsis">
      
        6. opendatalab MinerU2.5
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#small-models-2-4b-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Small Models (2-4B Parameters)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Small Models (2-4B Parameters)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#7-qwen3-vl-2b-instruct" class="md-nav__link">
    <span class="md-ellipsis">
      
        7. Qwen3-VL-2B-Instruct
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#8-deepseek-ocr" class="md-nav__link">
    <span class="md-ellipsis">
      
        8. DeepSeek-OCR
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#9-nanonets-ocr2-3b" class="md-nav__link">
    <span class="md-ellipsis">
      
        9. Nanonets-OCR2-3B
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#10-qwen3-vl-4b-instruct" class="md-nav__link">
    <span class="md-ellipsis">
      
        10. Qwen3-VL-4B-Instruct
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#11-google-gemma-3-4b-it" class="md-nav__link">
    <span class="md-ellipsis">
      
        11. Google Gemma-3-4B-IT
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#medium-models-7-9b-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Medium Models (7-9B Parameters)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Medium Models (7-9B Parameters)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#12-allenai-olmocr-2-7b-1025" class="md-nav__link">
    <span class="md-ellipsis">
      
        12. allenai olmOCR-2-7B-1025
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13-qwen3-vl-8b-instruct" class="md-nav__link">
    <span class="md-ellipsis">
      
        13. Qwen3-VL-8B-Instruct
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#14-datalab-to-chandra" class="md-nav__link">
    <span class="md-ellipsis">
      
        14. datalab-to Chandra
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#large-models-32b-parameters" class="md-nav__link">
    <span class="md-ellipsis">
      
        Large Models (32B+ Parameters)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Large Models (32B+ Parameters)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#15-qwen3-vl-32b-instruct" class="md-nav__link">
    <span class="md-ellipsis">
      
        15. Qwen3-VL-32B-Instruct
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#specialized-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Specialized Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Specialized Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#16-docling-projectdocling-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        16. docling-project/docling-models
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optional-models-legacyalternative" class="md-nav__link">
    <span class="md-ellipsis">
      
         Optional Models (Legacy/Alternative)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Optional Models (Legacy/Alternative)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qwen-25-vl-series-previous-generation" class="md-nav__link">
    <span class="md-ellipsis">
      
        Qwen 2.5-VL Series (Previous Generation)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Qwen 2.5-VL Series (Previous Generation)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#qwen25-vl-3b-instruct" class="md-nav__link">
    <span class="md-ellipsis">
      
        Qwen2.5-VL-3B-Instruct
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#qwen25-vl-7b-instruct" class="md-nav__link">
    <span class="md-ellipsis">
      
        Qwen2.5-VL-7B-Instruct
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-comparison-summary" class="md-nav__link">
    <span class="md-ellipsis">
      
         Model Comparison Summary
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Model Comparison Summary">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#by-release-date-2024-2026" class="md-nav__link">
    <span class="md-ellipsis">
      
        By Release Date (2024-2026)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#by-performance-olmocr-bench" class="md-nav__link">
    <span class="md-ellipsis">
      
        By Performance (OlmOCR-Bench)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#by-speed-relative-performance" class="md-nav__link">
    <span class="md-ellipsis">
      
        By Speed (Relative Performance)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#backend-support-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      
         Backend Support Matrix
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recommended-model-selection-guide" class="md-nav__link">
    <span class="md-ellipsis">
      
         Recommended Model Selection Guide
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Recommended Model Selection Guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#by-use-case" class="md-nav__link">
    <span class="md-ellipsis">
      
        By Use Case
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quick-start-examples" class="md-nav__link">
    <span class="md-ellipsis">
      
         Quick Start Examples
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Quick Start Examples">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ultra-compact-258m-granite-docling" class="md-nav__link">
    <span class="md-ellipsis">
      
        Ultra-Compact (258M) - Granite-Docling
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fastest-ocr-1b-lightonocr-2" class="md-nav__link">
    <span class="md-ellipsis">
      
        Fastest OCR (1B) - LightOnOCR-2
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#high-throughput-17b-dotsocr-vllm" class="md-nav__link">
    <span class="md-ellipsis">
      
        High-Throughput (1.7B) - dots.ocr + VLLM
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#best-accuracy-7-9b-olmocr-2-or-chandra" class="md-nav__link">
    <span class="md-ellipsis">
      
        Best Accuracy (7-9B) - olmOCR-2 or Chandra
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flexible-custom-layouts-8b-qwen3-vl" class="md-nav__link">
    <span class="md-ellipsis">
      
        Flexible Custom Layouts (8B) - Qwen3-VL
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#current-focus-layout-analysis-models" class="md-nav__link">
    <span class="md-ellipsis">
      
         Current Focus: Layout Analysis Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Current Focus: Layout Analysis Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phase-1-multi-backend-vlm-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 1: Multi-Backend VLM Integration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Phase 1: Multi-Backend VLM Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-qwen3-vl-8b-instruct-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        1. Qwen3-VL-8B-Instruct Integration
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Qwen3-VL-8B-Instruct Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation-checklist" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation Checklist:
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-2-additional-layout-models" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 2: Additional Layout Models
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Phase 2: Additional Layout Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#2-rt-detr-layout-detector" class="md-nav__link">
    <span class="md-ellipsis">
      
        2. RT-DETR Layout Detector
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-surya-layout-detector" class="md-nav__link">
    <span class="md-ellipsis">
      
        3. Surya Layout Detector
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-florence-2-layout-detector" class="md-nav__link">
    <span class="md-ellipsis">
      
        4. Florence-2 Layout Detector
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#future-phases" class="md-nav__link">
    <span class="md-ellipsis">
      
         Future Phases
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#success-metrics-layout-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
         Success Metrics (Layout Analysis)
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Success Metrics (Layout Analysis)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#performance-targets" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Targets
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#quality-targets" class="md-nav__link">
    <span class="md-ellipsis">
      
        Quality Targets
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#infrastructure" class="md-nav__link">
    <span class="md-ellipsis">
      
         Infrastructure
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Infrastructure">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#modal-deployment-standards" class="md-nav__link">
    <span class="md-ellipsis">
      
        Modal Deployment Standards
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpu-configurations" class="md-nav__link">
    <span class="md-ellipsis">
      
        GPU Configurations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
         References
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" References">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#design-documents" class="md-nav__link">
    <span class="md-ellipsis">
      
        Design Documents
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#external-resources" class="md-nav__link">
    <span class="md-ellipsis">
      
        External Resources
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes" class="md-nav__link">
    <span class="md-ellipsis">
      
         Notes
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label=" Notes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#implementation-order-rationale" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation Order Rationale
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#breaking-changes-from-v10" class="md-nav__link">
    <span class="md-ellipsis">
      
        Breaking Changes from v1.0
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/adithya-s-k/OmniDocs/blob/main/ROADMAP_DETAILED.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/adithya-s-k/OmniDocs/raw/main/ROADMAP_DETAILED.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="omnidocs-development-roadmap">OmniDocs Development Roadmap<a class="headerlink" href="#omnidocs-development-roadmap" title="Permanent link">&para;</a></h1>
<h2 id="target-model-support"> Target Model Support<a class="headerlink" href="#target-model-support" title="Permanent link">&para;</a></h2>
<blockquote>
<p><strong>Research Date</strong>: February 2026
<strong>Status</strong>: Comprehensive model research completed
<strong>Models Ordered By</strong>: Release date (newest first within each size category)</p>
</blockquote>
<hr />
<h2 id="quick-reference-model-capabilities-backend-support"> Quick Reference: Model Capabilities &amp; Backend Support<a class="headerlink" href="#quick-reference-model-capabilities-backend-support" title="Permanent link">&para;</a></h2>
<h3 id="comprehensive-model-comparison-table">Comprehensive Model Comparison Table<a class="headerlink" href="#comprehensive-model-comparison-table" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Size</th>
<th>PyTorch</th>
<th>VLLM</th>
<th>MLX</th>
<th>OpenAI API</th>
<th>Tasks</th>
<th>Release</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DeepSeek-OCR-2</strong></td>
<td>3B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O, Tab, F</td>
<td>Jan 2026</td>
</tr>
<tr>
<td><strong>LightOnOCR-2-1B</strong></td>
<td>1B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O</td>
<td>Jan 2026</td>
</tr>
<tr>
<td><strong>LightOnOCR-2-1B-bbox</strong></td>
<td>1B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, O</td>
<td>Jan 2026</td>
</tr>
<tr>
<td><strong>OCRFlux-3B</strong></td>
<td>3B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O</td>
<td>Jan 2026</td>
</tr>
<tr>
<td><strong>Qwen3-VL-2B</strong></td>
<td>2B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O, Tab</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>Qwen3-VL-4B</strong></td>
<td>4B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O, Tab</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>Qwen3-VL-8B</strong></td>
<td>8B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O, Tab, F</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>Qwen3-VL-32B</strong></td>
<td>32B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O, Tab, F</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>olmOCR-2-7B</strong></td>
<td>7B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O, Tab, F</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>PaddleOCR-VL</strong></td>
<td>900M</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, O, Tab, F</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>LightOnOCR-1B</strong></td>
<td>1B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O</td>
<td>Oct 2025</td>
</tr>
<tr>
<td><strong>Granite-Vision-3.3-2B</strong></td>
<td>2B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, Tab, Chart</td>
<td>Jun 2025</td>
</tr>
<tr>
<td><strong>Gemma-3-4B-IT</strong></td>
<td>4B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, S, O</td>
<td>2025</td>
</tr>
<tr>
<td><strong>Granite-Docling-258M</strong></td>
<td>258M</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, Tab, F</td>
<td>Dec 2024</td>
</tr>
<tr>
<td><strong>dots.ocr</strong></td>
<td>1.7B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, Tab, F, O</td>
<td>Dec 2024</td>
</tr>
<tr>
<td><strong>DeepSeek-OCR</strong></td>
<td>3B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O, Tab</td>
<td>Oct 2024</td>
</tr>
<tr>
<td><strong>Chandra</strong></td>
<td>9B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, O, Tab, F</td>
<td>2024</td>
</tr>
<tr>
<td><strong>MinerU2.5-2509-1.2B</strong></td>
<td>1.2B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, Tab, F, O</td>
<td>Sep 2024</td>
</tr>
<tr>
<td><strong>GOT-OCR2.0</strong></td>
<td>700M</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, O, F, Tab</td>
<td>Sep 2024</td>
</tr>
<tr>
<td><strong>Nanonets-OCR2-3B</strong></td>
<td>3B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, F, O</td>
<td>2024</td>
</tr>
<tr>
<td><strong>Qwen2.5-VL-3B</strong></td>
<td>3B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O</td>
<td>2024</td>
</tr>
<tr>
<td><strong>Qwen2.5-VL-7B</strong></td>
<td>7B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O, Tab</td>
<td>2024</td>
</tr>
<tr>
<td><strong>Qwen2.5-VL-32B</strong></td>
<td>32B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>T, L, S, O, Tab</td>
<td>2024</td>
</tr>
</tbody>
</table>
<p><strong>Legend:</strong>
- <strong>Tasks</strong>: T=Text Extract, L=Layout, O=OCR, S=Structured, Tab=Table, F=Formula, Chart=Chart Understanding
- <strong></strong> = Fully supported | <strong></strong> = Limited/Partial support | <strong></strong> = Not supported</p>
<hr />
<h3 id="backend-details">Backend Details<a class="headerlink" href="#backend-details" title="Permanent link">&para;</a></h3>
<h4 id="pytorch-support">PyTorch Support<a class="headerlink" href="#pytorch-support" title="Permanent link">&para;</a></h4>
<ul>
<li><strong>All models</strong> support PyTorch via HuggingFace Transformers</li>
<li>Primary development backend for all models</li>
<li>Requirements: <code>transformers&gt;=4.46</code>, <code>torch&gt;=2.0</code></li>
</ul>
<h4 id="vllm-support-high-throughput-production">VLLM Support (High-Throughput Production)<a class="headerlink" href="#vllm-support-high-throughput-production" title="Permanent link">&para;</a></h4>
<p><strong>Fully Supported</strong> ():
- Qwen3-VL Series (vllm&gt;=0.11.0)
- Qwen2.5-VL Series
- DeepSeek-OCR (official upstream)
- dots.ocr (recommended, vllm&gt;=0.9.1)
- MinerU2.5
- olmOCR-2 (via olmOCR toolkit)
- Chandra
- LightOnOCR-2-1B (vllm&gt;=0.11.1)
- Nanonets-OCR2-3B</p>
<p><strong>Limited Support</strong> ():
- Granite-Docling-258M (untied weights required)
- PaddleOCR-VL (possible but not officially confirmed)</p>
<p><strong>Not Supported</strong> ():
- GOT-OCR2.0
- Gemma-3-4B-IT
- LightOnOCR-1B (legacy)</p>
<h4 id="mlx-support-apple-silicon-m1m2m3">MLX Support (Apple Silicon M1/M2/M3+)<a class="headerlink" href="#mlx-support-apple-silicon-m1m2m3" title="Permanent link">&para;</a></h4>
<p><strong>Fully Supported</strong> via mlx-community ():
- <strong>Qwen3-VL Series</strong> - <a href="https://huggingface.co/collections/mlx-community/qwen3-vl">Collection</a>
  - 2B, 4B, 8B, 32B (4-bit, 8-bit variants)
- <strong>Qwen2.5-VL Series</strong> - <a href="https://huggingface.co/collections/mlx-community/qwen25-vl">Collection</a>
  - 3B, 7B, 32B, 72B (4-bit, 8-bit variants)
- <strong>DeepSeek-OCR</strong> - <a href="https://huggingface.co/mlx-community/DeepSeek-OCR-4bit">4-bit</a>, <a href="https://huggingface.co/mlx-community/DeepSeek-OCR-8bit">8-bit</a>
- <strong>Granite-Docling-258M</strong> - <a href="https://huggingface.co/ibm-granite/granite-docling-258M-mlx">Official MLX</a>
- <strong>MinerU2.5</strong> - <a href="https://huggingface.co/mlx-community/MinerU2.5-2509-1.2B-bf16">bf16</a>
- <strong>Nanonets-OCR2-3B</strong> - <a href="https://huggingface.co/mlx-community/Nanonets-OCR2-3B-4bit">4-bit</a></p>
<p><strong>Usage</strong>:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pip<span class="w"> </span>install<span class="w"> </span>mlx-vlm
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>python<span class="w"> </span>-m<span class="w"> </span>mlx_vlm.generate<span class="w"> </span>--model<span class="w"> </span>mlx-community/Qwen3-VL-8B-Instruct-4bit<span class="w"> </span><span class="se">\</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="w">  </span>--prompt<span class="w"> </span><span class="s2">&quot;Extract text from this document&quot;</span><span class="w"> </span>--image<span class="w"> </span>doc.png
</span></code></pre></div></p>
<h4 id="openai-compatible-api-providers">OpenAI-Compatible API Providers<a class="headerlink" href="#openai-compatible-api-providers" title="Permanent link">&para;</a></h4>
<p><strong>OpenRouter</strong> (<a href="https://openrouter.ai">openrouter.ai</a>):
-  Qwen3-VL-235B-A22B ($0.45/$3.50 per M tokens)
-  Qwen3-VL-30B-A3B
-  Qwen2.5-VL-3B (SOTA visual understanding)
-  Qwen2.5-VL-32B (structured outputs, math)
-  Qwen2.5-VL-72B (best overall)</p>
<p><strong>Novita AI</strong> (<a href="https://novita.ai">novita.ai</a>):
-  DeepSeek-OCR (<a href="https://novita.ai/models/model-detail/deepseek-deepseek-ocr">Model Page</a>)
-  Qwen2.5-VL-72B (OCR + scientific reasoning)
-  Qwen3-VL-8B ($0.08/$0.50 per M tokens)</p>
<p><strong>Together AI</strong> (<a href="https://www.together.ai/models">together.ai</a>):
-  Various vision-language models
-  Lightweight models with multilingual support</p>
<p><strong>Replicate</strong> (<a href="https://replicate.com/collections/vision-models">replicate.com</a>):
-  Vision models collection
-  Pay-per-use inference</p>
<p><strong>Others</strong>:
- DeepInfra: olmOCR-2-7B
- Parasail: olmOCR-2-7B
- Cirrascale: olmOCR-2-7B</p>
<p><strong>API Integration Example</strong>:
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction</span><span class="w"> </span><span class="kn">import</span> <span class="n">QwenTextExtractor</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction.qwen</span><span class="w"> </span><span class="kn">import</span> <span class="n">QwenAPIConfig</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="c1"># OpenRouter</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">QwenTextExtractor</span><span class="p">(</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="n">backend</span><span class="o">=</span><span class="n">QwenAPIConfig</span><span class="p">(</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;qwen/qwen3-vl-8b-instruct&quot;</span><span class="p">,</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>        <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;YOUR_OPENROUTER_KEY&quot;</span><span class="p">,</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>        <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;https://openrouter.ai/api/v1&quot;</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="p">)</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="p">)</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="c1"># Novita AI</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">QwenTextExtractor</span><span class="p">(</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    <span class="n">backend</span><span class="o">=</span><span class="n">QwenAPIConfig</span><span class="p">(</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;novita/qwen3-vl-8b-instruct&quot;</span><span class="p">,</span>
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>        <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;YOUR_NOVITA_KEY&quot;</span><span class="p">,</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>        <span class="n">base_url</span><span class="o">=</span><span class="s2">&quot;https://api.novita.ai/v3/openai&quot;</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    <span class="p">)</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a><span class="p">)</span>
</span></code></pre></div></p>
<hr />
<h3 id="task-capability-matrix">Task Capability Matrix<a class="headerlink" href="#task-capability-matrix" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Task</th>
<th>Description</th>
<th>Model Count</th>
<th>Top Models</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Text Extract</strong> (T)</td>
<td>Document  Markdown/HTML</td>
<td>18</td>
<td>LightOnOCR-2, Chandra, Qwen3-VL-8B</td>
</tr>
<tr>
<td><strong>Layout</strong> (L)</td>
<td>Structure detection with bboxes</td>
<td>8</td>
<td>Qwen3-VL-8B, Chandra, MinerU2.5</td>
</tr>
<tr>
<td><strong>OCR</strong> (O)</td>
<td>Text + bbox coordinates</td>
<td>15</td>
<td>LightOnOCR-2, olmOCR-2, Chandra</td>
</tr>
<tr>
<td><strong>Structured</strong> (S)</td>
<td>Schema-based extraction</td>
<td>5</td>
<td>Qwen3-VL (all), Qwen2.5-VL (all), Gemma-3</td>
</tr>
<tr>
<td><strong>Table</strong> (Tab)</td>
<td>Table detection/extraction</td>
<td>12</td>
<td>Qwen3-VL-8B, DeepSeek-OCR, olmOCR-2</td>
</tr>
<tr>
<td><strong>Formula</strong> (F)</td>
<td>Math expression recognition</td>
<td>8</td>
<td>Nanonets-OCR2, Qwen3-VL-8B, GOT-OCR2.0</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="model-overview-by-task-capability">Model Overview by Task Capability<a class="headerlink" href="#model-overview-by-task-capability" title="Permanent link">&para;</a></h2>
<h3 id="task-categories">Task Categories<a class="headerlink" href="#task-categories" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Task</th>
<th>Description</th>
<th>Model Count</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>text_extract</strong></td>
<td>Document to Markdown/HTML conversion</td>
<td>18</td>
</tr>
<tr>
<td><strong>layout</strong></td>
<td>Document structure detection with bounding boxes</td>
<td>8</td>
</tr>
<tr>
<td><strong>ocr</strong></td>
<td>Text extraction with bbox coordinates</td>
<td>6</td>
</tr>
<tr>
<td><strong>structured</strong></td>
<td>Schema-based data extraction</td>
<td>5</td>
</tr>
<tr>
<td><strong>table</strong></td>
<td>Table detection and extraction</td>
<td>4</td>
</tr>
<tr>
<td><strong>formula</strong></td>
<td>Mathematical expression recognition</td>
<td>3</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="latest-models-january-2026"> Latest Models (January 2026)<a class="headerlink" href="#latest-models-january-2026" title="Permanent link">&para;</a></h2>
<h3 id="deepseek-ocr-2">DeepSeek-OCR-2<a class="headerlink" href="#deepseek-ocr-2" title="Permanent link">&para;</a></h3>
<p><strong>Released</strong>: January 27, 2026 | <strong>Parameters</strong>: 3B | <strong>License</strong>: MIT</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR-2">deepseek-ai/DeepSeek-OCR-2</a></p>
<p><strong>Description</strong>: State-of-the-art 3B-parameter vision-language model with new DeepEncoder architecture. Unlike traditional OCR systems, DeepSeek OCR 2 focuses on image-to-text with stronger visual reasoning.</p>
<p><strong>Key Features</strong>:
- DeepEncoder: 380M vision encoder (80M SAM-base + 300M CLIP-large)
- 97% precision at 10 visual token compression
- ~60% accuracy at 20 compression
- Strong document understanding beyond text extraction</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (high throughput)
-  MLX (4-bit, 8-bit)
-  API (Novita AI, OpenRouter)</p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR-2">Model Card</a>
- <a href="https://github.com/deepseek-ai/DeepSeek-OCR">GitHub</a></p>
<hr />
<h3 id="lightonocr-2-1b">LightOnOCR-2-1B<a class="headerlink" href="#lightonocr-2-1b" title="Permanent link">&para;</a></h3>
<p><strong>Released</strong>: January 19, 2026 | <strong>Parameters</strong>: 1B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/lightonai/LightOnOCR-2-1B">lightonai/LightOnOCR-2-1B</a></p>
<p><strong>Description</strong>: Second-generation 1B-parameter end-to-end vision-language OCR model. SOTA conversion of PDF renders to clean text without multi-stage pipelines.</p>
<p><strong>Key Features</strong>:
- <strong>83.2 on OlmOCR-Bench</strong> (SOTA, beats 9B Chandra)
- 5.7 pages/second on H100 (~493K pages/day)
- &lt;$0.01 per 1,000 pages at cloud pricing
- Bbox variant for figure/image localization</p>
<p><strong>Model Variants</strong>:
- <code>LightOnOCR-2-1B</code> - Default OCR
- <code>LightOnOCR-2-1B-bbox</code> - Best localization
- <code>LightOnOCR-2-1B-bbox-soup</code> - Balanced</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (transformers from source)
-  VLLM (vllm&gt;=0.11.1)</p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code>, <code>layout</code> (bbox variants)</p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/blog/lightonai/lightonocr-2">Blog Post</a>
- <a href="https://huggingface.co/spaces/lightonai/LightOnOCR-2-1B-Demo">Demo</a></p>
<hr />
<h3 id="ocrflux-3b">OCRFlux-3B<a class="headerlink" href="#ocrflux-3b" title="Permanent link">&para;</a></h3>
<p><strong>Released</strong>: January 2026 | <strong>Parameters</strong>: 3B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: Fine-tuned from Qwen2.5-VL-3B-Instruct</p>
<p><strong>Description</strong>: Multimodal LLM for converting PDFs and images to clean Markdown. Runs efficiently on consumer hardware (GTX 3090).</p>
<p><strong>Key Features</strong>:
- Compact 3B architecture
- Clean Markdown output
- Consumer GPU compatible
- Based on Qwen2.5-VL</p>
<p><strong>Backends Supported</strong>:
-  PyTorch
-  VLLM</p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code></p>
<hr />
<h2 id="core-models-by-size-release-date"> Core Models (By Size &amp; Release Date)<a class="headerlink" href="#core-models-by-size-release-date" title="Permanent link">&para;</a></h2>
<h3 id="ultra-compact-models-1b-parameters">Ultra-Compact Models (&lt;1B Parameters)<a class="headerlink" href="#ultra-compact-models-1b-parameters" title="Permanent link">&para;</a></h3>
<h4 id="ibm-granite-docling-258m">IBM Granite-Docling-258M<a class="headerlink" href="#ibm-granite-docling-258m" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: December 2024 | <strong>Parameters</strong>: 258M | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/ibm-granite/granite-docling-258M">ibm-granite/granite-docling-258M</a></p>
<p><strong>Description</strong>: Ultra-compact vision-language model (VLM) for converting documents to machine-readable formats while fully preserving layout, tables, equations, and lists. Built on Idefics3 architecture with siglip2-base-patch16-512 vision encoder and Granite 165M LLM.</p>
<p><strong>Key Features</strong>:
- End-to-end document understanding at 258M parameters
- Handles inline/floating math, code, table structure
- Rivals systems several times its size
- Extremely cost-effective</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  MLX (Apple Silicon) - <a href="https://huggingface.co/ibm-granite/granite-docling-258M-mlx">ibm-granite/granite-docling-258M-mlx</a>
-  WebGPU - <a href="https://huggingface.co/spaces/ibm-granite/granite-docling-258M-WebGPU">Demo Space</a></p>
<p><strong>Integration</strong>:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>pip<span class="w"> </span>install<span class="w"> </span>docling<span class="w">  </span><span class="c1"># Automatically downloads model</span>
</span></code></pre></div></p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>pillow</code>, <code>docling</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/ibm-granite/granite-docling-258M">Model Card</a>
- <a href="https://huggingface.co/ibm-granite/granite-docling-258M-mlx">MLX Version</a>
- <a href="https://huggingface.co/spaces/ibm-granite/granite-docling-258m-demo">Demo Space</a>
- <a href="https://www.ibm.com/granite/docs/models/docling">Official Docs</a>
- <a href="https://huggingface.co/collections/ibm-granite/granite-docling">Collection</a></p>
<hr />
<h4 id="2-stepfun-ai-got-ocr20">2. stepfun-ai GOT-OCR2.0<a class="headerlink" href="#2-stepfun-ai-got-ocr20" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: September 2024 | <strong>Parameters</strong>: 700M | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/stepfun-ai/GOT-OCR2_0">stepfun-ai/GOT-OCR2_0</a></p>
<p><strong>Description</strong>: General OCR Theory model for multilingual OCR on plain documents, scene text, formatted documents, tables, charts, mathematical formulas, geometric shapes, molecular formulas, and sheet music.</p>
<p><strong>Key Features</strong>:
- Interactive OCR with region-specific recognition (coordinate or color-based)
- Plain text OCR + formatted text OCR (markdown, LaTeX)
- Multi-page document processing
- Wide range of specialized content types</p>
<p><strong>Model Variations</strong>:
- <strong>stepfun-ai/GOT-OCR2_0</strong> - Original with custom code
- <strong>stepfun-ai/GOT-OCR-2.0-hf</strong> - HuggingFace-native transformers integration</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  Custom inference pipeline</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>pillow</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code>, <code>formula</code>, <code>table</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/stepfun-ai/GOT-OCR2_0">Model Card</a>
- <a href="https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf">HF-Native Version</a></p>
<hr />
<h3 id="compact-models-1-2b-parameters">Compact Models (1-2B Parameters)<a class="headerlink" href="#compact-models-1-2b-parameters" title="Permanent link">&para;</a></h3>
<h4 id="3-rednote-hilab-dotsocr">3. rednote-hilab dots.ocr<a class="headerlink" href="#3-rednote-hilab-dotsocr" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: December 2024 | <strong>Parameters</strong>: 1.7B | <strong>License</strong>: MIT</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/rednote-hilab/dots.ocr">rednote-hilab/dots.ocr</a></p>
<p><strong>Description</strong>: Multilingual documents parsing model based on 1.7B LLM with SOTA performance. Provides faster inference than many high-performing models based on larger foundations.</p>
<p><strong>Key Features</strong>:
- Task switching via prompt alteration only
- Competitive detection vs traditional models (DocLayout-YOLO)
- Built-in VLLM support for high throughput
- Released with paper <a href="https://huggingface.co/papers/2512.02498">arXiv:2512.02498</a></p>
<p><strong>Model Variations</strong>:
- <strong>rednote-hilab/dots.ocr</strong> - Full model
- <strong>rednote-hilab/dots.ocr.base</strong> - Base variant</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (Recommended for production) - vLLM 0.9.1+</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>vllm&gt;=0.9.1</code> (recommended)</p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>table</code>, <code>formula</code>, <code>ocr</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/rednote-hilab/dots.ocr">Model Card</a>
- <a href="https://github.com/rednote-hilab/dots.ocr">GitHub</a>
- <a href="https://dotsocr.xiaohongshu.com">Live Demo</a>
- <a href="https://huggingface.co/papers/2512.02498">Paper</a>
- <a href="https://huggingface.co/collections/rednote-hilab/dotsocr">Collection</a></p>
<hr />
<h4 id="4-paddlepaddle-paddleocr-vl">4. PaddlePaddle PaddleOCR-VL<a class="headerlink" href="#4-paddlepaddle-paddleocr-vl" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2025 | <strong>Parameters</strong>: 900M | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL">PaddlePaddle/PaddleOCR-VL</a></p>
<p><strong>Description</strong>: Ultra-compact multilingual documents parsing VLM with SOTA performance. Integrates NaViT-style dynamic resolution visual encoder with ERNIE-4.5-0.3B language model.</p>
<p><strong>Key Features</strong>:
- Supports 109 languages
- Excels in recognizing complex elements (text, tables, formulas, charts)
- Minimal resource consumption
- Fast inference speeds
- SOTA in page-level parsing and element-level recognition</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers - officially integrated)
-  PaddlePaddle framework</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>paddlepaddle</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>ocr</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/PaddlePaddle/PaddleOCR-VL">Model Card</a>
- <a href="https://huggingface.co/spaces/PaddlePaddle/PaddleOCR-VL_Online_Demo">Online Demo</a>
- <a href="https://huggingface.co/collections/PaddlePaddle/paddleocr-vl">Collection</a>
- <a href="https://huggingface.co/docs/transformers/en/model_doc/paddleocr_vl">Transformers Docs</a>
- <a href="https://github.com/PaddlePaddle/PaddleOCR">GitHub - PaddleOCR</a></p>
<hr />
<h4 id="5-lighton-ai-lightonocr-series">5. LightOn AI LightOnOCR Series<a class="headerlink" href="#5-lighton-ai-lightonocr-series" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: January 2025 (v2), October 2025 (v1) | <strong>Parameters</strong>: 1B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace Models</strong>:
- <a href="https://huggingface.co/lightonai/LightOnOCR-2-1B">lightonai/LightOnOCR-2-1B</a> - <strong>Recommended</strong> for OCR
- <a href="https://huggingface.co/lightonai/LightOnOCR-2-1B-bbox">lightonai/LightOnOCR-2-1B-bbox</a> - Best localization
- <a href="https://huggingface.co/lightonai/LightOnOCR-2-1B-bbox-soup">lightonai/LightOnOCR-2-1B-bbox-soup</a> - Balanced OCR + bbox
- <a href="https://huggingface.co/lightonai/LightOnOCR-1B-1025">lightonai/LightOnOCR-1B-1025</a> - Legacy v1</p>
<p><strong>Description</strong>: Compact, end-to-end vision-language model for OCR and document understanding. State-of-the-art accuracy in its weight class while being several times faster than larger VLMs.</p>
<p><strong>Key Features</strong>:
- <strong>LightOnOCR-2-1B</strong>: SOTA on OlmOCR-Bench (83.2  0.9), outperforms Chandra-9B
- <strong>Performance</strong>: 3.3 faster than Chandra, 1.7 faster than OlmOCR, 5 faster than dots.ocr
- <strong>Variants</strong>: OCR-only, bbox-capable (figure/image localization), and balanced checkpoints
- Paper: <a href="https://arxiv.org/html/2601.14251">arXiv:2601.14251</a></p>
<p><strong>Model Comparison</strong>:
| Model | Use Case | Bbox Support |
|-------|----------|--------------|
| LightOnOCR-2-1B | Default for PDFText/Markdown |  |
| LightOnOCR-2-1B-bbox | Best localization of figures/images |  Best |
| LightOnOCR-2-1B-bbox-soup | Balanced OCR + localization |  Balanced |</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers - upstream support)
-  Requires transformers from source for v2 (not yet in stable release)</p>
<p><strong>Quantized Versions</strong>:
- <a href="https://huggingface.co/Mungert/LightOnOCR-1B-1025-GGUF">GGUF format</a></p>
<p><strong>Dependencies</strong>: <code>transformers&gt;=4.48</code> (from source for v2), <code>torch</code>, <code>pillow</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code>, <code>layout</code> (bbox variants only)</p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/blog/lightonai/lightonocr-2">LightOnOCR-2 Blog</a>
- <a href="https://huggingface.co/blog/lightonai/lightonocr">LightOnOCR-1 Blog</a>
- <a href="https://huggingface.co/spaces/lightonai/LightOnOCR-2-1B-Demo">Demo Space</a>
- <a href="https://arxiv.org/html/2601.14251">Paper (arXiv)</a>
- <a href="https://huggingface.co/lightonai">Organization</a></p>
<hr />
<h4 id="6-opendatalab-mineru25">6. opendatalab MinerU2.5<a class="headerlink" href="#6-opendatalab-mineru25" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: September 2024 | <strong>Parameters</strong>: 1.2B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B">opendatalab/MinerU2.5-2509-1.2B</a></p>
<p><strong>Description</strong>: Decoupled vision-language model for efficient high-resolution document parsing with state-of-the-art accuracy and low computational overhead.</p>
<p><strong>Key Features</strong>:
- Two-stage parsing: global layout analysis on downsampled images  fine-grained content recognition on native-resolution crops
- Outperforms Gemini-2.5 Pro, Qwen2.5-VL-72B, GPT-4o, MonkeyOCR, dots.ocr, PP-StructureV3
- Large-scale diverse data engine for pretraining/fine-tuning
- New performance records in text, formula, table recognition, and reading order</p>
<p><strong>Model Variations</strong>:
- <strong>opendatalab/MinerU2.5-2509-1.2B</strong> - Official model
- <strong>mlx-community/MinerU2.5-2509-1.2B-bf16</strong> - MLX for Apple Silicon
- <strong>Mungert/MinerU2.5-2509-1.2B-GGUF</strong> - GGUF quantized</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (with OpenAI API specs)
-  MLX (Apple Silicon)</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>vllm</code> (optional)</p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>table</code>, <code>formula</code>, <code>ocr</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/opendatalab/MinerU2.5-2509-1.2B">Model Card</a>
- <a href="https://arxiv.org/html/2509.22186v2">Paper (arXiv:2509.22186)</a>
- <a href="https://huggingface.co/mlx-community/MinerU2.5-2509-1.2B-bf16">MLX Version</a>
- <a href="https://huggingface.co/Mungert/MinerU2.5-2509-1.2B-GGUF">GGUF Version</a></p>
<hr />
<h3 id="small-models-2-4b-parameters">Small Models (2-4B Parameters)<a class="headerlink" href="#small-models-2-4b-parameters" title="Permanent link">&para;</a></h3>
<h4 id="7-qwen3-vl-2b-instruct">7. Qwen3-VL-2B-Instruct<a class="headerlink" href="#7-qwen3-vl-2b-instruct" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2025 | <strong>Parameters</strong>: 2B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct">Qwen/Qwen3-VL-2B-Instruct</a></p>
<p><strong>Description</strong>: Multimodal LLM from Alibaba Cloud's Qwen team with comprehensive upgrades: superior text understanding/generation, deeper visual perception/reasoning, extended context, and stronger agent interaction.</p>
<p><strong>Key Features</strong>:
- Dense and MoE architectures that scale from edge to cloud
- Instruct and reasoning-enhanced "Thinking" editions
- Enhanced spatial and video dynamics comprehension
- Part of Qwen3-VL multimodal retrieval framework (arXiv:2601.04720, 2026)</p>
<p><strong>Model Variations</strong>:
- <strong>Qwen/Qwen3-VL-2B-Instruct</strong> - Instruction-tuned
- <strong>Qwen/Qwen3-VL-2B-Thinking</strong> - Reasoning-enhanced
- <strong>Qwen/Qwen3-VL-2B-Instruct-GGUF</strong> - Quantized GGUF</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM
-  MLX (via mlx-community)
-  API (via cloud providers)</p>
<p><strong>Dependencies</strong>: <code>transformers&gt;=4.46</code>, <code>torch</code>, <code>qwen-vl-utils</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>structured</code>, <code>ocr</code>, <code>table</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct">Model Card</a>
- <a href="https://github.com/QwenLM/Qwen3-VL">GitHub</a>
- <a href="https://huggingface.co/collections/Qwen/qwen3-vl">Collection</a>
- <a href="https://huggingface.co/Qwen/Qwen3-VL-2B-Instruct-GGUF">GGUF Version</a></p>
<hr />
<h4 id="8-deepseek-ocr">8. DeepSeek-OCR<a class="headerlink" href="#8-deepseek-ocr" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2024 | <strong>Parameters</strong>: ~3B | <strong>License</strong>: MIT</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR">deepseek-ai/DeepSeek-OCR</a></p>
<p><strong>Description</strong>: High-accuracy OCR model from DeepSeek-AI for extracting text from complex visual inputs (documents, screenshots, receipts, natural scenes).</p>
<p><strong>Key Features</strong>:
- Built for real-world documents: PDFs, forms, tables, handwritten/noisy text
- Outputs clean, structured Markdown
- VLLM support upstream
- ~2500 tokens/s on A100 with vLLM
- Paper: <a href="https://arxiv.org/abs/2510.18234">arXiv:2510.18234</a></p>
<p><strong>Model Variations</strong>:
- <strong>deepseek-ai/DeepSeek-OCR</strong> - Official BF16 (~6.7 GB)
- <strong>NexaAI/DeepSeek-OCR-GGUF</strong> - Quantized GGUF</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (officially supported)</p>
<p><strong>Requirements</strong>:
- Python 3.12.9 + CUDA 11.8
- <code>torch==2.6.0</code>, <code>transformers==4.46.3</code>, <code>flash-attn==2.7.3</code>
- L4 / A100 GPUs (16 GB VRAM)</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>vllm</code>, <code>flash-attn</code>, <code>einops</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code>, <code>table</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/deepseek-ai/DeepSeek-OCR">Model Card</a>
- <a href="https://github.com/deepseek-ai/DeepSeek-OCR">GitHub</a>
- <a href="https://huggingface.co/NexaAI/DeepSeek-OCR-GGUF">GGUF Version</a>
- <a href="https://huggingface.co/spaces/merterbak/DeepSeek-OCR-Demo">Demo Space</a></p>
<hr />
<h4 id="9-nanonets-ocr2-3b">9. Nanonets-OCR2-3B<a class="headerlink" href="#9-nanonets-ocr2-3b" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: 2024 | <strong>Parameters</strong>: 3B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/nanonets/Nanonets-OCR2-3B">nanonets/Nanonets-OCR2-3B</a></p>
<p><strong>Description</strong>: State-of-the-art image-to-markdown OCR model that transforms documents into structured markdown with intelligent content recognition and semantic tagging, optimized for LLM downstream processing.</p>
<p><strong>Key Features</strong>:
- LaTeX equation recognition (inline $...$ and display $$...$$)
- Intelligent image description with structured tags (logos, charts, graphs)
- 125K context window
- ~7.53 GB model size</p>
<p><strong>Model Variations</strong>:
- <strong>nanonets/Nanonets-OCR2-3B</strong> - Full BF16
- <strong>Mungert/Nanonets-OCR2-3B-GGUF</strong> - GGUF quantized
- <strong>mlx-community/Nanonets-OCR2-3B-4bit</strong> - MLX 4-bit
- <strong>yasserrmd/Nanonets-OCR2-3B</strong> - Ollama format</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  MLX (Apple Silicon)
-  Ollama</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>pillow</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>formula</code>, <code>ocr</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/nanonets/Nanonets-OCR2-3B">Model Card</a>
- <a href="https://huggingface.co/Mungert/Nanonets-OCR2-3B-GGUF">GGUF Version</a>
- <a href="https://huggingface.co/mlx-community/Nanonets-OCR2-3B-4bit">MLX 4-bit</a>
- <a href="https://ollama.com/yasserrmd/Nanonets-OCR2-3B">Ollama</a></p>
<hr />
<h4 id="10-qwen3-vl-4b-instruct">10. Qwen3-VL-4B-Instruct<a class="headerlink" href="#10-qwen3-vl-4b-instruct" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2025 | <strong>Parameters</strong>: 4B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct">Qwen/Qwen3-VL-4B-Instruct</a></p>
<p><strong>Description</strong>: Mid-size Qwen3-VL model with balanced performance and efficiency. Part of comprehensive multimodal model series with text understanding, visual reasoning, and agent capabilities.</p>
<p><strong>Model Variations</strong>:
- <strong>Qwen/Qwen3-VL-4B-Instruct</strong> - Instruction-tuned
- <strong>Qwen/Qwen3-VL-4B-Thinking</strong> - Reasoning-enhanced</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM
-  MLX (via mlx-community)
-  API (via cloud providers)</p>
<p><strong>Dependencies</strong>: <code>transformers&gt;=4.46</code>, <code>torch</code>, <code>qwen-vl-utils</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>structured</code>, <code>ocr</code>, <code>table</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/collections/Qwen/qwen3-vl">Collection</a>
- <a href="https://github.com/QwenLM/Qwen3-VL">GitHub</a></p>
<hr />
<h4 id="11-google-gemma-3-4b-it">11. Google Gemma-3-4B-IT<a class="headerlink" href="#11-google-gemma-3-4b-it" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: 2025 | <strong>Parameters</strong>: 4B | <strong>License</strong>: Gemma License</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/google/gemma-3-4b-it">google/gemma-3-4b-it</a></p>
<p><strong>Description</strong>: Lightweight, state-of-the-art multimodal model from Google built from same research/technology as Gemini. Handles text and image input, generates text output.</p>
<p><strong>Key Features</strong>:
- 128K context window
- Multilingual support (140+ languages)
- SigLIP image encoder (896896 square images)
- Gemma-3-4B-IT beats Gemma-2-27B-IT on benchmarks</p>
<p><strong>Model Variations</strong>:
- <strong>google/gemma-3-4b-it</strong> - Instruction-tuned (vision-capable)
- <strong>google/gemma-3-4b-pt</strong> - Pre-trained base
- <strong>google/gemma-3-4b-it-qat-q4_0-gguf</strong> - Quantized GGUF
- <strong>bartowski/google_gemma-3-4b-it-GGUF</strong> - Community GGUF</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  Google AI SDK
-  API (Google AI Studio)</p>
<p><strong>Dependencies</strong>: <code>transformers&gt;=4.46</code>, <code>torch</code>, <code>pillow</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>structured</code>, <code>ocr</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/google/gemma-3-4b-it">Model Card</a>
- <a href="https://huggingface.co/blog/gemma3">Blog Post</a>
- <a href="https://huggingface.co/docs/transformers/en/model_doc/gemma3">Transformers Docs</a>
- <a href="https://ai.google.dev/gemma/docs/huggingface_inference">Google Docs</a>
- <a href="https://deepmind.google/models/gemma/gemma-3/">DeepMind Page</a></p>
<hr />
<h3 id="medium-models-7-9b-parameters">Medium Models (7-9B Parameters)<a class="headerlink" href="#medium-models-7-9b-parameters" title="Permanent link">&para;</a></h3>
<h4 id="12-allenai-olmocr-2-7b-1025">12. allenai olmOCR-2-7B-1025<a class="headerlink" href="#12-allenai-olmocr-2-7b-1025" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2025 | <strong>Parameters</strong>: 7B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/allenai/olmOCR-2-7B-1025">allenai/olmOCR-2-7B-1025</a></p>
<p><strong>Description</strong>: State-of-the-art OCR for English-language digitized print documents. Fine-tuned from Qwen2.5-VL-7B-Instruct using olmOCR-mix-1025 dataset + GRPO RL training.</p>
<p><strong>Key Features</strong>:
- 82.4 points on olmOCR-Bench (SOTA for real-world documents)
- Substantial improvements where OCR often fails (math equations, tables, tricky cases)
- Boosted via reinforcement learning (GRPO)</p>
<p><strong>Model Variations</strong>:
- <strong>allenai/olmOCR-2-7B-1025</strong> - Full BF16 version
- <strong>allenai/olmOCR-2-7B-1025-FP8</strong> - <strong>Recommended</strong> FP8 quantized (practical use except fine-tuning)
- <strong>bartowski/allenai_olmOCR-2-7B-1025-GGUF</strong> - GGUF quantized
- <strong>richardyoung/olmOCR-2-7B-1025-GGUF</strong> - Alternative GGUF</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (recommended via olmOCR toolkit)
-  API (DeepInfra, Parasail, Cirrascale)</p>
<p><strong>Best Usage</strong>: Via olmOCR toolkit with VLLM for efficient inference at scale (millions of documents).</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>vllm</code>, <code>olmocr</code> (toolkit
<strong>Tasks</strong>: <code>text_extract</code>, <code>ocr</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/allenai/olmOCR-2-7B-1025">Model Card</a>
- <a href="https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8">FP8 Version</a>
- <a href="https://allenai.org/blog/olmocr-2">Blog Post</a>
- <a href="https://huggingface.co/bartowski/allenai_olmOCR-2-7B-1025-GGUF">GGUF (bartowski)</a></p>
<hr />
<h4 id="13-qwen3-vl-8b-instruct">13. Qwen3-VL-8B-Instruct<a class="headerlink" href="#13-qwen3-vl-8b-instruct" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2025 | <strong>Parameters</strong>: 8B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct">Qwen/Qwen3-VL-8B-Instruct</a></p>
<p><strong>Description</strong>: Primary model in Qwen3-VL series with optimal balance of performance and efficiency. Enhanced document parsing over Qwen2.5-VL with improved visual perception, text understanding, and advanced reasoning.</p>
<p><strong>Key Features</strong>:
- Custom layout label support (flexible VLM)
- Extended context length
- Enhanced spatial and video comprehension
- Stronger agent interaction capabilities</p>
<p><strong>Model Variations</strong>:
- <strong>Qwen/Qwen3-VL-8B-Instruct</strong> - Instruction-tuned
- <strong>Qwen/Qwen3-VL-8B-Thinking</strong> - Reasoning-enhanced</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM
-  MLX (Apple Silicon) - <a href="https://huggingface.co/mlx-community/Qwen3-VL-8B-Instruct-4bit">mlx-community/Qwen3-VL-8B-Instruct-4bit</a>
-  API (Novita AI, OpenRouter, etc.)</p>
<p><strong>API Providers</strong>:
- <strong>Novita AI</strong>: Context 131K tokens, Max output 33K tokens
  - Pricing: $0.08/M input tokens, $0.50/M output tokens</p>
<p><strong>Dependencies</strong>: <code>transformers&gt;=4.46</code>, <code>torch</code>, <code>qwen-vl-utils</code>, <code>vllm</code> (optional)</p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>structured</code>, <code>ocr</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct">Model Card</a>
- <a href="https://huggingface.co/collections/Qwen/qwen3-vl">Collection</a>
- <a href="https://github.com/QwenLM/Qwen3-VL">GitHub</a>
- <a href="https://huggingface.co/mlx-community/Qwen3-VL-8B-Instruct-4bit">MLX 4-bit</a></p>
<hr />
<h4 id="14-datalab-to-chandra">14. datalab-to Chandra<a class="headerlink" href="#14-datalab-to-chandra" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: 2024 | <strong>Parameters</strong>: 9B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/datalab-to/chandra">datalab-to/chandra</a></p>
<p><strong>Description</strong>: OCR model handling complex tables, forms, and handwriting with full layout preservation. Uses Qwen3VL for document understanding.</p>
<p><strong>Key Features</strong>:
- 83.1  0.9 overall on OlmOCR benchmark (outperforms DeepSeek OCR, dots.ocr, olmOCR)
- Strong grounding capabilities
- Supports 40+ languages
- Layout-aware output with bbox coordinates for every text block, table, and image
- Outputs in HTML, Markdown, and JSON with detailed layout</p>
<p><strong>Use Cases</strong>:
- Handwritten forms
- Mathematical notation
- Multi-column layouts
- Complex tables</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (production throughput)</p>
<p><strong>Installation</strong>:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>pip<span class="w"> </span>install<span class="w"> </span>chandra-ocr
</span></code></pre></div></p>
<p><strong>Model Variations</strong>:
- <strong>datalab-to/chandra</strong> - Official model
- <strong>noctrex/Chandra-OCR-GGUF</strong> - GGUF quantized</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>vllm</code> (optional), <code>chandra-ocr</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>ocr</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/datalab-to/chandra">Model Card</a>
- <a href="https://github.com/datalab-to/chandra">GitHub</a>
- <a href="https://www.datalab.to/blog/introducing-chandra">Blog Post</a>
- <a href="https://deepwiki.com/datalab-to/chandra">DeepWiki Docs</a>
- <a href="https://huggingface.co/noctrex/Chandra-OCR-GGUF">GGUF Version</a></p>
<hr />
<h3 id="large-models-32b-parameters">Large Models (32B+ Parameters)<a class="headerlink" href="#large-models-32b-parameters" title="Permanent link">&para;</a></h3>
<h4 id="15-qwen3-vl-32b-instruct">15. Qwen3-VL-32B-Instruct<a class="headerlink" href="#15-qwen3-vl-32b-instruct" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: October 2025 | <strong>Parameters</strong>: 32B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/Qwen/Qwen3-VL-32B-Instruct">Qwen/Qwen3-VL-32B-Instruct</a></p>
<p><strong>Description</strong>: Largest Qwen3-VL model with maximum performance for complex document understanding and multimodal reasoning tasks.</p>
<p><strong>Key Features</strong>:
- Superior performance on complex documents
- Extended context length
- Enhanced reasoning capabilities
- Production-grade for demanding applications</p>
<p><strong>Model Variations</strong>:
- <strong>Qwen/Qwen3-VL-32B-Instruct</strong> - Instruction-tuned
- <strong>Qwen/Qwen3-VL-32B-Thinking</strong> - Reasoning-enhanced</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM (recommended for production)
-  API (cloud providers)</p>
<p><strong>GPU Requirements</strong>: A100 40GB+ or multi-GPU setup</p>
<p><strong>Dependencies</strong>: <code>transformers&gt;=4.46</code>, <code>torch</code>, <code>qwen-vl-utils</code>, <code>vllm</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>structured</code>, <code>ocr</code>, <code>table</code>, <code>formula</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/Qwen/Qwen3-VL-32B-Instruct">Model Card</a>
- <a href="https://huggingface.co/collections/Qwen/qwen3-vl">Collection</a>
- <a href="https://github.com/QwenLM/Qwen3-VL">GitHub</a></p>
<hr />
<h3 id="specialized-models">Specialized Models<a class="headerlink" href="#specialized-models" title="Permanent link">&para;</a></h3>
<h4 id="16-docling-projectdocling-models">16. docling-project/docling-models<a class="headerlink" href="#16-docling-projectdocling-models" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: 2024 | <strong>Parameters</strong>: Various | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/docling-project/docling-models">docling-project/docling-models</a></p>
<p><strong>Description</strong>: Collection of models powering the Docling PDF document conversion package. Includes layout detection (RT-DETR) and table structure recognition (TableFormer).</p>
<p><strong>Models Included</strong>:
1. <strong>Layout Model</strong>: RT-DETR for detecting document components
   - Labels: Caption, Footnote, Formula, List-item, Page-footer, Page-header, Picture, Section-header, Table, Text, Title
2. <strong>TableFormer Model</strong>: Table structure identification from images</p>
<p><strong>Note</strong>: Superseded by <strong>granite-docling-258M</strong> for end-to-end document conversion (receives updates and support).</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (via Docling library)</p>
<p><strong>Integration</strong>:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>pip<span class="w"> </span>install<span class="w"> </span>docling
</span></code></pre></div></p>
<p><strong>Dependencies</strong>: <code>docling</code>, <code>transformers</code>, <code>torch</code></p>
<p><strong>Tasks</strong>: <code>layout</code>, <code>table</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/docling-project/docling-models">Model Card</a>
- <a href="https://docling-project.github.io/docling/usage/vision_models/">Vision Models Docs</a>
- <a href="https://huggingface.co/docling-project/SmolDocling-256M-preview">SmolDocling (legacy)</a></p>
<hr />
<h2 id="optional-models-legacyalternative"> Optional Models (Legacy/Alternative)<a class="headerlink" href="#optional-models-legacyalternative" title="Permanent link">&para;</a></h2>
<h3 id="qwen-25-vl-series-previous-generation">Qwen 2.5-VL Series (Previous Generation)<a class="headerlink" href="#qwen-25-vl-series-previous-generation" title="Permanent link">&para;</a></h3>
<h4 id="qwen25-vl-3b-instruct">Qwen2.5-VL-3B-Instruct<a class="headerlink" href="#qwen25-vl-3b-instruct" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: 2024 | <strong>Parameters</strong>: 3B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct">Qwen/Qwen2.5-VL-3B-Instruct</a></p>
<p><strong>Description</strong>: Previous generation Qwen VLM with strong visual understanding, agentic capabilities, video understanding (1+ hour), and structured outputs.</p>
<p><strong>Key Features</strong>:
- Analyzes texts, charts, icons, graphics, layouts
- Visual agent capabilities (computer use, phone use)
- Video comprehension with temporal segment pinpointing
- ViT architecture with SwiGLU and RMSNorm
- Dynamic resolution + dynamic FPS sampling</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM
-  MLX
-  API</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>qwen-vl-utils</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>structured</code>, <code>ocr</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct">Model Card</a>
- <a href="https://huggingface.co/collections/Qwen/qwen25-vl">Collection</a></p>
<hr />
<h4 id="qwen25-vl-7b-instruct">Qwen2.5-VL-7B-Instruct<a class="headerlink" href="#qwen25-vl-7b-instruct" title="Permanent link">&para;</a></h4>
<p><strong>Released</strong>: 2024 | <strong>Parameters</strong>: 7B | <strong>License</strong>: Apache 2.0</p>
<p><strong>HuggingFace</strong>: <a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct">Qwen/Qwen2.5-VL-7B-Instruct</a></p>
<p><strong>Description</strong>: Mid-size Qwen2.5-VL model with same capabilities as 3B variant but enhanced performance.</p>
<p><strong>Model Variations</strong>:
- <strong>Qwen/Qwen2.5-VL-7B-Instruct</strong> - Official
- <strong>unsloth/Qwen2.5-VL-7B-Instruct-GGUF</strong> - GGUF quantized
- <strong>nvidia/Qwen2.5-VL-7B-Instruct-NVFP4</strong> - NVIDIA FP4 optimized</p>
<p><strong>Backends Supported</strong>:
-  PyTorch (HuggingFace Transformers)
-  VLLM
-  MLX
-  API</p>
<p><strong>Dependencies</strong>: <code>transformers</code>, <code>torch</code>, <code>qwen-vl-utils</code></p>
<p><strong>Tasks</strong>: <code>text_extract</code>, <code>layout</code>, <code>structured</code>, <code>ocr</code>, <code>table</code></p>
<p><strong>Links</strong>:
- <a href="https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct">Model Card</a>
- <a href="https://huggingface.co/collections/Qwen/qwen25-vl">Collection</a>
- <a href="https://huggingface.co/unsloth/Qwen2.5-VL-7B-Instruct-GGUF">GGUF Version</a></p>
<hr />
<h2 id="model-comparison-summary"> Model Comparison Summary<a class="headerlink" href="#model-comparison-summary" title="Permanent link">&para;</a></h2>
<h3 id="by-release-date-2024-2026">By Release Date (2024-2026)<a class="headerlink" href="#by-release-date-2024-2026" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Release</th>
<th>Params</th>
<th>Benchmark Score</th>
</tr>
</thead>
<tbody>
<tr>
<td>LightOnOCR-2-1B</td>
<td>Jan 2025</td>
<td>1B</td>
<td>83.2 (OlmOCR)</td>
</tr>
<tr>
<td>dots.ocr</td>
<td>Dec 2024</td>
<td>1.7B</td>
<td>79.1 (OlmOCR)</td>
</tr>
<tr>
<td>Granite-Docling-258M</td>
<td>Dec 2024</td>
<td>258M</td>
<td>N/A</td>
</tr>
<tr>
<td>Chandra</td>
<td>2024</td>
<td>9B</td>
<td>83.1 (OlmOCR)</td>
</tr>
<tr>
<td>Qwen3-VL Series</td>
<td>Oct 2025</td>
<td>2-32B</td>
<td>SOTA</td>
</tr>
<tr>
<td>PaddleOCR-VL</td>
<td>Oct 2025</td>
<td>900M</td>
<td>SOTA</td>
</tr>
<tr>
<td>olmOCR-2-7B</td>
<td>Oct 2025</td>
<td>7B</td>
<td>82.4 (OlmOCR)</td>
</tr>
<tr>
<td>DeepSeek-OCR</td>
<td>Oct 2024</td>
<td>3B</td>
<td>75.4 (OlmOCR)</td>
</tr>
<tr>
<td>GOT-OCR2.0</td>
<td>Sep 2024</td>
<td>700M</td>
<td>N/A</td>
</tr>
<tr>
<td>MinerU2.5</td>
<td>Sep 2024</td>
<td>1.2B</td>
<td>SOTA</td>
</tr>
</tbody>
</table>
<h3 id="by-performance-olmocr-bench">By Performance (OlmOCR-Bench)<a class="headerlink" href="#by-performance-olmocr-bench" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Rank</th>
<th>Model</th>
<th>Score</th>
<th>Params</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>LightOnOCR-2-1B</td>
<td>83.2  0.9</td>
<td>1B</td>
</tr>
<tr>
<td>2</td>
<td>Chandra</td>
<td>83.1  0.9</td>
<td>9B</td>
</tr>
<tr>
<td>3</td>
<td>olmOCR-2-7B</td>
<td>82.4</td>
<td>7B</td>
</tr>
<tr>
<td>4</td>
<td>dots.ocr</td>
<td>79.1</td>
<td>1.7B</td>
</tr>
<tr>
<td>5</td>
<td>olmOCR (v1)</td>
<td>78.5</td>
<td>7B</td>
</tr>
<tr>
<td>6</td>
<td>DeepSeek-OCR</td>
<td>75.4  1.0</td>
<td>3B</td>
</tr>
</tbody>
</table>
<h3 id="by-speed-relative-performance">By Speed (Relative Performance)<a class="headerlink" href="#by-speed-relative-performance" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Model</th>
<th>Speed Multiplier</th>
<th>Params</th>
</tr>
</thead>
<tbody>
<tr>
<td>LightOnOCR-2-1B</td>
<td><strong>Fastest baseline</strong></td>
<td>1B</td>
</tr>
<tr>
<td>PaddleOCR-VL</td>
<td>1.73 slower</td>
<td>900M</td>
</tr>
<tr>
<td>DeepSeek-OCR (vLLM)</td>
<td>1.73 slower</td>
<td>3B</td>
</tr>
<tr>
<td>olmOCR-2</td>
<td>1.7 slower</td>
<td>7B</td>
</tr>
<tr>
<td>Chandra</td>
<td>3.3 slower</td>
<td>9B</td>
</tr>
<tr>
<td>dots.ocr</td>
<td>5 slower</td>
<td>1.7B</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="backend-support-matrix"> Backend Support Matrix<a class="headerlink" href="#backend-support-matrix" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>PyTorch</th>
<th>VLLM</th>
<th>MLX</th>
<th>API</th>
<th>GGUF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Granite-Docling-258M</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dots.ocr</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>GOT-OCR2.0</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>PaddleOCR-VL</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>MinerU2.5</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>LightOnOCR-2-1B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Qwen3-VL (all)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DeepSeek-OCR</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Nanonets-OCR2-3B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Gemma-3-4B-IT</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>olmOCR-2-7B</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Chandra</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Qwen2.5-VL (all)</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="recommended-model-selection-guide"> Recommended Model Selection Guide<a class="headerlink" href="#recommended-model-selection-guide" title="Permanent link">&para;</a></h2>
<h3 id="by-use-case">By Use Case<a class="headerlink" href="#by-use-case" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Use Case</th>
<th>Recommended Model</th>
<th>Why</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Edge/Mobile Deployment</strong></td>
<td>Granite-Docling-258M</td>
<td>Ultra-compact (258M), MLX support</td>
</tr>
<tr>
<td><strong>Fast OCR (CPU)</strong></td>
<td>LightOnOCR-2-1B</td>
<td>Fastest in class, SOTA accuracy</td>
</tr>
<tr>
<td><strong>Multilingual Documents</strong></td>
<td>PaddleOCR-VL</td>
<td>109 languages, minimal resources</td>
</tr>
<tr>
<td><strong>High-Throughput Serving</strong></td>
<td>dots.ocr + VLLM</td>
<td>Built for VLLM, fast inference</td>
</tr>
<tr>
<td><strong>Best Accuracy (English)</strong></td>
<td>LightOnOCR-2-1B or Chandra</td>
<td>SOTA on OlmOCR-Bench</td>
</tr>
<tr>
<td><strong>Custom Layout Detection</strong></td>
<td>Qwen3-VL-8B</td>
<td>Flexible VLM with prompt-based labels</td>
</tr>
<tr>
<td><strong>Production Balanced</strong></td>
<td>Qwen3-VL-8B or olmOCR-2-7B</td>
<td>Performance + reliability</td>
</tr>
<tr>
<td><strong>Complex Documents</strong></td>
<td>Chandra or Qwen3-VL-32B</td>
<td>Handles tables, forms, handwriting</td>
</tr>
<tr>
<td><strong>Apple Silicon (M1/M2/M3)</strong></td>
<td>Granite-Docling-258M (MLX)</td>
<td>Native MLX optimization</td>
</tr>
<tr>
<td><strong>Cost-Effective API</strong></td>
<td>Qwen3-VL-8B (Novita)</td>
<td>$0.08/M tokens input</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="quick-start-examples"> Quick Start Examples<a class="headerlink" href="#quick-start-examples" title="Permanent link">&para;</a></h2>
<h3 id="ultra-compact-258m-granite-docling">Ultra-Compact (258M) - Granite-Docling<a class="headerlink" href="#ultra-compact-258m-granite-docling" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction</span><span class="w"> </span><span class="kn">import</span> <span class="n">GraniteDoclingOCR</span><span class="p">,</span> <span class="n">GraniteDoclingConfig</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">GraniteDoclingOCR</span><span class="p">(</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>    <span class="n">config</span><span class="o">=</span><span class="n">GraniteDoclingConfig</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="p">)</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="n">result</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;markdown&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="fastest-ocr-1b-lightonocr-2">Fastest OCR (1B) - LightOnOCR-2<a class="headerlink" href="#fastest-ocr-1b-lightonocr-2" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction</span><span class="w"> </span><span class="kn">import</span> <span class="n">LightOnOCRExtractor</span><span class="p">,</span> <span class="n">LightOnOCRConfig</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">LightOnOCRExtractor</span><span class="p">(</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>    <span class="n">config</span><span class="o">=</span><span class="n">LightOnOCRConfig</span><span class="p">(</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;lightonai/LightOnOCR-2-1B&quot;</span><span class="p">,</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>    <span class="p">)</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="p">)</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="n">result</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;markdown&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="high-throughput-17b-dotsocr-vllm">High-Throughput (1.7B) - dots.ocr + VLLM<a class="headerlink" href="#high-throughput-17b-dotsocr-vllm" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction</span><span class="w"> </span><span class="kn">import</span> <span class="n">DotsOCRTextExtractor</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction.dotsocr</span><span class="w"> </span><span class="kn">import</span> <span class="n">DotsOCRVLLMConfig</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">DotsOCRTextExtractor</span><span class="p">(</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    <span class="n">backend</span><span class="o">=</span><span class="n">DotsOCRVLLMConfig</span><span class="p">(</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;rednote-hilab/dots.ocr&quot;</span><span class="p">,</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>        <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>        <span class="n">gpu_memory_utilization</span><span class="o">=</span><span class="mf">0.9</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>    <span class="p">)</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="p">)</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="n">result</span> <span class="o">=</span> <span class="n">extractor</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_format</span><span class="o">=</span><span class="s2">&quot;markdown&quot;</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="best-accuracy-7-9b-olmocr-2-or-chandra">Best Accuracy (7-9B) - olmOCR-2 or Chandra<a class="headerlink" href="#best-accuracy-7-9b-olmocr-2-or-chandra" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction</span><span class="w"> </span><span class="kn">import</span> <span class="n">OlmOCRExtractor</span><span class="p">,</span> <span class="n">ChandraTextExtractor</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction.olm</span><span class="w"> </span><span class="kn">import</span> <span class="n">OlmOCRVLLMConfig</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.text_extraction.chandra</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChandraPyTorchConfig</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="c1"># Option 1: olmOCR-2-7B with VLLM</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">OlmOCRExtractor</span><span class="p">(</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>    <span class="n">backend</span><span class="o">=</span><span class="n">OlmOCRVLLMConfig</span><span class="p">(</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;allenai/olmOCR-2-7B-1025-FP8&quot;</span><span class="p">,</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>        <span class="n">tensor_parallel_size</span><span class="o">=</span><span class="mi">1</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>    <span class="p">)</span>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a><span class="p">)</span>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a><span class="c1"># Option 2: Chandra-9B</span>
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a><span class="n">extractor</span> <span class="o">=</span> <span class="n">ChandraTextExtractor</span><span class="p">(</span>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>    <span class="n">backend</span><span class="o">=</span><span class="n">ChandraPyTorchConfig</span><span class="p">(</span>
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;datalab-to/chandra&quot;</span><span class="p">,</span>
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span>
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>    <span class="p">)</span>
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a><span class="p">)</span>
</span></code></pre></div>
<h3 id="flexible-custom-layouts-8b-qwen3-vl">Flexible Custom Layouts (8B) - Qwen3-VL<a class="headerlink" href="#flexible-custom-layouts-8b-qwen3-vl" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.layout_extraction</span><span class="w"> </span><span class="kn">import</span> <span class="n">QwenLayoutDetector</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">omnidocs.tasks.layout_extraction.qwen</span><span class="w"> </span><span class="kn">import</span> <span class="n">QwenPyTorchConfig</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="n">layout</span> <span class="o">=</span> <span class="n">QwenLayoutDetector</span><span class="p">(</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>    <span class="n">backend</span><span class="o">=</span><span class="n">QwenPyTorchConfig</span><span class="p">(</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>        <span class="n">model</span><span class="o">=</span><span class="s2">&quot;Qwen/Qwen3-VL-8B-Instruct&quot;</span><span class="p">,</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>    <span class="p">)</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="p">)</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span class="n">result</span> <span class="o">=</span> <span class="n">layout</span><span class="o">.</span><span class="n">extract</span><span class="p">(</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>    <span class="n">image</span><span class="p">,</span>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>    <span class="n">custom_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;code_block&quot;</span><span class="p">,</span> <span class="s2">&quot;sidebar&quot;</span><span class="p">,</span> <span class="s2">&quot;diagram&quot;</span><span class="p">]</span>
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a><span class="p">)</span>
</span></code></pre></div>
<hr />
<h2 id="current-focus-layout-analysis-models"> Current Focus: Layout Analysis Models<a class="headerlink" href="#current-focus-layout-analysis-models" title="Permanent link">&para;</a></h2>
<h3 id="phase-1-multi-backend-vlm-integration">Phase 1: Multi-Backend VLM Integration<a class="headerlink" href="#phase-1-multi-backend-vlm-integration" title="Permanent link">&para;</a></h3>
<h4 id="1-qwen3-vl-8b-instruct-integration">1. Qwen3-VL-8B-Instruct Integration<a class="headerlink" href="#1-qwen3-vl-8b-instruct-integration" title="Permanent link">&para;</a></h4>
<p><strong>Status</strong>:  In Progress</p>
<p>Integrate Qwen3-VL-8B-Instruct for flexible layout detection with custom label support across all backends.</p>
<p><strong>Key Features</strong>:
- Enhanced document parsing over Qwen2.5-VL
- Improved visual perception and text understanding
- Advanced reasoning capabilities
- Custom layout label support</p>
<h5 id="implementation-checklist">Implementation Checklist:<a class="headerlink" href="#implementation-checklist" title="Permanent link">&para;</a></h5>
<ul>
<li>[ ] <strong>HuggingFace/PyTorch Backend</strong> (<code>QwenLayoutDetector</code> + <code>QwenPyTorchConfig</code>)</li>
</ul>
<p><strong>Model</strong>: <code>Qwen/Qwen3-VL-8B-Instruct</code></p>
<p><strong>Config Class</strong>: <code>omnidocs/tasks/layout_analysis/qwen/pytorch.py</code>
  <div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">QwenPyTorchConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen3-VL-8B-Instruct&quot;</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>    <span class="n">torch_dtype</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="s2">&quot;float16&quot;</span><span class="p">,</span> <span class="s2">&quot;bfloat16&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>    <span class="n">attn_implementation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># &quot;flash_attention_2&quot; if available</span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>    <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span></code></pre></div></p>
<p><strong>Dependencies</strong>:
  - <code>torch</code>, <code>transformers</code>
  - <code>qwen-vl-utils</code> (model-specific utility)</p>
<p><strong>Reference Implementation</strong>: See <code>scripts/layout/modal_qwen3_vl_layout.py</code> in the repository</p>
<p><strong>Testing</strong>:
  - Validate on synthetic document images
  - Compare detection accuracy with ground truth
  - Test custom label support</p>
<ul>
<li>[ ] <strong>VLLM Backend</strong> (<code>QwenVLLMConfig</code>)</li>
</ul>
<p><strong>Model</strong>: <code>Qwen/Qwen3-VL-8B-Instruct</code></p>
<p><strong>Config Class</strong>: <code>omnidocs/tasks/layout_analysis/qwen/vllm.py</code>
  <div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">QwenVLLMConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen3-VL-8B-Instruct&quot;</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>    <span class="n">tensor_parallel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>    <span class="n">gpu_memory_utilization</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>    <span class="n">max_model_len</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="n">trust_remote_code</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
</span></code></pre></div></p>
<p><strong>Dependencies</strong>:
  - <code>vllm&gt;=0.4.0</code>
  - <code>torch&gt;=2.0</code></p>
<p><strong>Use Case</strong>: High-throughput batch processing (10+ documents/second)</p>
<p><strong>Modal Config</strong>:
  - GPU: <code>A10G:1</code> (minimum), <code>A100:1</code> (recommended for production)
  - Image: VLLM GPU Image with flash-attn</p>
<p><strong>Testing</strong>:
  - Benchmark throughput vs PyTorch
  - Validate output consistency
  - Test batch processing</p>
<ul>
<li>[ ] <strong>MLX Backend</strong> (<code>QwenMLXConfig</code>)</li>
</ul>
<p><strong>Model</strong>: <code>mlx-community/Qwen3-VL-8B-Instruct-4bit</code></p>
<p><strong>Config Class</strong>: <code>omnidocs/tasks/layout_analysis/qwen/mlx.py</code>
  <div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">QwenMLXConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;mlx-community/Qwen3-VL-8B-Instruct-4bit&quot;</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>    <span class="n">quantization</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;4bit&quot;</span><span class="p">,</span> <span class="s2">&quot;8bit&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;4bit&quot;</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>    <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span>
</span></code></pre></div></p>
<p><strong>Dependencies</strong>:
  - <code>mlx&gt;=0.10</code>
  - <code>mlx-lm&gt;=0.10</code></p>
<p><strong>Platform</strong>: Apple Silicon only (M1/M2/M3+)</p>
<p><strong>Use Case</strong>: Local development and testing on macOS</p>
<p><strong>Note</strong>:  DO NOT deploy MLX to Modal - local development only</p>
<ul>
<li>[ ] <strong>API Backend</strong> (<code>QwenAPIConfig</code>)</li>
</ul>
<p><strong>Model</strong>: <code>qwen3-vl-8b-instruct</code></p>
<p><strong>Config Class</strong>: <code>omnidocs/tasks/layout_analysis/qwen/api.py</code>
  <div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">QwenAPIConfig</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>    <span class="n">model</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;novita/qwen3-vl-8b-instruct&quot;</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>    <span class="n">api_key</span><span class="p">:</span> <span class="nb">str</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>    <span class="n">base_url</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="__span-13-5"><a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>    <span class="n">max_tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4096</span>
</span><span id="__span-13-6"><a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>    <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span>
</span></code></pre></div></p>
<p><strong>Provider</strong>: Novita AI
  - <strong>Context Length</strong>: 131K tokens
  - <strong>Max Output</strong>: 33K tokens
  - <strong>Pricing</strong>:
    - Input: $0.08/M tokens
    - Output: $0.50/M tokens</p>
<p><strong>Dependencies</strong>:
  - <code>litellm&gt;=1.30</code>
  - <code>openai&gt;=1.0</code></p>
<p><strong>Use Case</strong>:
  - Serverless deployments
  - No GPU infrastructure required
  - Cost-effective for low-volume processing</p>
<ul>
<li>[ ] <strong>Main Extractor Class</strong> (<code>omnidocs/tasks/layout_analysis/qwen.py</code>)</li>
</ul>
<p>Implement unified <code>QwenLayoutDetector</code> class:
  <div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
</span><span id="__span-14-3"><a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseLayoutExtractor</span>
</span><span id="__span-14-4"><a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">LayoutOutput</span>
</span><span id="__span-14-5"><a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a><span class="kn">from</span><span class="w"> </span><span class="nn">.qwen</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
</span><span id="__span-14-6"><a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>    <span class="n">QwenPyTorchConfig</span><span class="p">,</span>
</span><span id="__span-14-7"><a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>    <span class="n">QwenVLLMConfig</span><span class="p">,</span>
</span><span id="__span-14-8"><a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>    <span class="n">QwenMLXConfig</span><span class="p">,</span>
</span><span id="__span-14-9"><a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>    <span class="n">QwenAPIConfig</span><span class="p">,</span>
</span><span id="__span-14-10"><a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a><span class="p">)</span>
</span><span id="__span-14-11"><a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>
</span><span id="__span-14-12"><a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a><span class="n">QwenBackendConfig</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span>
</span><span id="__span-14-13"><a id="__codelineno-14-13" name="__codelineno-14-13" href="#__codelineno-14-13"></a>    <span class="n">QwenPyTorchConfig</span><span class="p">,</span>
</span><span id="__span-14-14"><a id="__codelineno-14-14" name="__codelineno-14-14" href="#__codelineno-14-14"></a>    <span class="n">QwenVLLMConfig</span><span class="p">,</span>
</span><span id="__span-14-15"><a id="__codelineno-14-15" name="__codelineno-14-15" href="#__codelineno-14-15"></a>    <span class="n">QwenMLXConfig</span><span class="p">,</span>
</span><span id="__span-14-16"><a id="__codelineno-14-16" name="__codelineno-14-16" href="#__codelineno-14-16"></a>    <span class="n">QwenAPIConfig</span><span class="p">,</span>
</span><span id="__span-14-17"><a id="__codelineno-14-17" name="__codelineno-14-17" href="#__codelineno-14-17"></a><span class="p">]</span>
</span><span id="__span-14-18"><a id="__codelineno-14-18" name="__codelineno-14-18" href="#__codelineno-14-18"></a>
</span><span id="__span-14-19"><a id="__codelineno-14-19" name="__codelineno-14-19" href="#__codelineno-14-19"></a><span class="k">class</span><span class="w"> </span><span class="nc">QwenLayoutDetector</span><span class="p">(</span><span class="n">BaseLayoutExtractor</span><span class="p">):</span>
</span><span id="__span-14-20"><a id="__codelineno-14-20" name="__codelineno-14-20" href="#__codelineno-14-20"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Flexible VLM-based layout detector with custom label support.&quot;&quot;&quot;</span>
</span><span id="__span-14-21"><a id="__codelineno-14-21" name="__codelineno-14-21" href="#__codelineno-14-21"></a>
</span><span id="__span-14-22"><a id="__codelineno-14-22" name="__codelineno-14-22" href="#__codelineno-14-22"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backend</span><span class="p">:</span> <span class="n">QwenBackendConfig</span><span class="p">):</span>
</span><span id="__span-14-23"><a id="__codelineno-14-23" name="__codelineno-14-23" href="#__codelineno-14-23"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">backend_config</span> <span class="o">=</span> <span class="n">backend</span>
</span><span id="__span-14-24"><a id="__codelineno-14-24" name="__codelineno-14-24" href="#__codelineno-14-24"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">_backend</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_backend</span><span class="p">()</span>
</span><span id="__span-14-25"><a id="__codelineno-14-25" name="__codelineno-14-25" href="#__codelineno-14-25"></a>
</span><span id="__span-14-26"><a id="__codelineno-14-26" name="__codelineno-14-26" href="#__codelineno-14-26"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">extract</span><span class="p">(</span>
</span><span id="__span-14-27"><a id="__codelineno-14-27" name="__codelineno-14-27" href="#__codelineno-14-27"></a>        <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-14-28"><a id="__codelineno-14-28" name="__codelineno-14-28" href="#__codelineno-14-28"></a>        <span class="n">image</span><span class="p">:</span> <span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">,</span>
</span><span id="__span-14-29"><a id="__codelineno-14-29" name="__codelineno-14-29" href="#__codelineno-14-29"></a>        <span class="n">custom_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-14-30"><a id="__codelineno-14-30" name="__codelineno-14-30" href="#__codelineno-14-30"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LayoutOutput</span><span class="p">:</span>
</span><span id="__span-14-31"><a id="__codelineno-14-31" name="__codelineno-14-31" href="#__codelineno-14-31"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-14-32"><a id="__codelineno-14-32" name="__codelineno-14-32" href="#__codelineno-14-32"></a><span class="sd">        Detect layout elements with optional custom labels.</span>
</span><span id="__span-14-33"><a id="__codelineno-14-33" name="__codelineno-14-33" href="#__codelineno-14-33"></a>
</span><span id="__span-14-34"><a id="__codelineno-14-34" name="__codelineno-14-34" href="#__codelineno-14-34"></a><span class="sd">        Args:</span>
</span><span id="__span-14-35"><a id="__codelineno-14-35" name="__codelineno-14-35" href="#__codelineno-14-35"></a><span class="sd">            image: PIL Image</span>
</span><span id="__span-14-36"><a id="__codelineno-14-36" name="__codelineno-14-36" href="#__codelineno-14-36"></a><span class="sd">            custom_labels: Optional custom layout categories</span>
</span><span id="__span-14-37"><a id="__codelineno-14-37" name="__codelineno-14-37" href="#__codelineno-14-37"></a><span class="sd">                Default: [&quot;title&quot;, &quot;paragraph&quot;, &quot;table&quot;, &quot;figure&quot;,</span>
</span><span id="__span-14-38"><a id="__codelineno-14-38" name="__codelineno-14-38" href="#__codelineno-14-38"></a><span class="sd">                         &quot;caption&quot;, &quot;formula&quot;, &quot;list&quot;]</span>
</span><span id="__span-14-39"><a id="__codelineno-14-39" name="__codelineno-14-39" href="#__codelineno-14-39"></a>
</span><span id="__span-14-40"><a id="__codelineno-14-40" name="__codelineno-14-40" href="#__codelineno-14-40"></a><span class="sd">        Returns:</span>
</span><span id="__span-14-41"><a id="__codelineno-14-41" name="__codelineno-14-41" href="#__codelineno-14-41"></a><span class="sd">            LayoutOutput with detected bounding boxes</span>
</span><span id="__span-14-42"><a id="__codelineno-14-42" name="__codelineno-14-42" href="#__codelineno-14-42"></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="__span-14-43"><a id="__codelineno-14-43" name="__codelineno-14-43" href="#__codelineno-14-43"></a>        <span class="c1"># Implementation...</span>
</span></code></pre></div></p>
<ul>
<li>[ ] <strong>Integration Tests</strong></li>
</ul>
<p>Test suite covering:
  - All backend configurations
  - Custom label functionality
  - Cross-backend output consistency
  - Edge cases (empty images, single elements, complex layouts)</p>
<ul>
<li>
<p>[ ] <strong>Documentation</strong></p>
</li>
<li>
<p>API reference with examples for each backend</p>
</li>
<li>Performance comparison table (PyTorch vs VLLM vs MLX vs API)</li>
<li>Migration guide from Qwen2.5-VL</li>
<li>
<p>Custom label usage examples</p>
</li>
<li>
<p>[ ] <strong>Modal Deployment Script</strong></p>
</li>
</ul>
<p>Create production-ready deployment:
  - <code>scripts/layout_omnidocs/modal_qwen_layout_vllm_online.py</code>
  - Web endpoint for layout detection API
  - Batch processing support
  - Monitoring and logging</p>
<hr />
<h3 id="phase-2-additional-layout-models">Phase 2: Additional Layout Models<a class="headerlink" href="#phase-2-additional-layout-models" title="Permanent link">&para;</a></h3>
<h4 id="2-rt-detr-layout-detector">2. RT-DETR Layout Detector<a class="headerlink" href="#2-rt-detr-layout-detector" title="Permanent link">&para;</a></h4>
<ul>
<li>[ ] <strong>Single-Backend Implementation</strong> (PyTorch only)</li>
<li>Model: <code>RT-DETR</code> (Facebook AI)</li>
<li>Fixed label support (COCO-based)</li>
<li>Real-time detection optimization</li>
</ul>
<h4 id="3-surya-layout-detector">3. Surya Layout Detector<a class="headerlink" href="#3-surya-layout-detector" title="Permanent link">&para;</a></h4>
<ul>
<li>[ ] <strong>Single-Backend Implementation</strong> (PyTorch only)</li>
<li>Model: <code>vikp/surya_layout</code></li>
<li>Multi-language document support</li>
<li>Optimized for speed</li>
</ul>
<h4 id="4-florence-2-layout-detector">4. Florence-2 Layout Detector<a class="headerlink" href="#4-florence-2-layout-detector" title="Permanent link">&para;</a></h4>
<ul>
<li>[ ] <strong>Multi-Backend Implementation</strong></li>
<li>HuggingFace/PyTorch backend</li>
<li>API backend (Microsoft Azure)</li>
<li>Object detection + dense captioning</li>
</ul>
<hr />
<h2 id="future-phases"> Future Phases<a class="headerlink" href="#future-phases" title="Permanent link">&para;</a></h2>
<p>Additional task categories will be added after layout analysis is complete:</p>
<ul>
<li><strong>OCR Extraction</strong>: Surya-OCR, PaddleOCR, Qwen-OCR</li>
<li><strong>Text Extraction</strong>: VLM-based Markdown/HTML extraction</li>
<li><strong>Table Extraction</strong>: Table Transformer, Surya-Table</li>
<li><strong>Math Expression Extraction</strong>: UniMERNet, Surya-Math</li>
<li><strong>Advanced Features</strong>: Reading order, image captioning, chart understanding</li>
<li><strong>Package &amp; Distribution</strong>: PyPI publishing, comprehensive documentation</li>
</ul>
<hr />
<h2 id="success-metrics-layout-analysis"> Success Metrics (Layout Analysis)<a class="headerlink" href="#success-metrics-layout-analysis" title="Permanent link">&para;</a></h2>
<h3 id="performance-targets">Performance Targets<a class="headerlink" href="#performance-targets" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Metric</th>
<th>Target</th>
<th>Current</th>
</tr>
</thead>
<tbody>
<tr>
<td>Layout Detection Accuracy (mAP)</td>
<td>&gt;90%</td>
<td>TBD</td>
</tr>
<tr>
<td>Inference Speed (PyTorch)</td>
<td>&lt;2s per page</td>
<td>TBD</td>
</tr>
<tr>
<td>Inference Speed (VLLM)</td>
<td>&lt;0.5s per page</td>
<td>TBD</td>
</tr>
<tr>
<td>Custom Label Support</td>
<td>100% functional</td>
<td>TBD</td>
</tr>
</tbody>
</table>
<h3 id="quality-targets">Quality Targets<a class="headerlink" href="#quality-targets" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] Type hints coverage: 100%</li>
<li>[ ] Docstring coverage: 100%</li>
<li>[ ] Test coverage: &gt;80%</li>
<li>[ ] All backends tested on production data</li>
<li>[ ] Cross-backend output consistency validated</li>
</ul>
<hr />
<h2 id="infrastructure"> Infrastructure<a class="headerlink" href="#infrastructure" title="Permanent link">&para;</a></h2>
<h3 id="modal-deployment-standards">Modal Deployment Standards<a class="headerlink" href="#modal-deployment-standards" title="Permanent link">&para;</a></h3>
<p><strong>Consistency Requirements</strong> (as per CLAUDE.md):</p>
<ul>
<li>Volume Name: <code>omnidocs</code></li>
<li>Secret Name: <code>adithya-hf-wandb</code></li>
<li>CUDA Version: <code>12.4.0-devel-ubuntu22.04</code></li>
<li>Python Version: <code>3.11</code> (3.12 for Qwen3-VL)</li>
<li>Cache Directory: <code>/data/.cache</code> (HuggingFace)</li>
<li>Model Cache: <code>/data/omnidocs_models</code></li>
<li>Dependency Management: <code>.uv_pip_install()</code> (NO version pinning)</li>
</ul>
<h3 id="gpu-configurations">GPU Configurations<a class="headerlink" href="#gpu-configurations" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>GPU</th>
<th>Use Case</th>
<th>Cost (est.)</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>A10G:1</code></td>
<td>Development &amp; Testing</td>
<td>$0.60/hr</td>
</tr>
<tr>
<td><code>A100:1</code></td>
<td>Production Inference</td>
<td>$3.00/hr</td>
</tr>
<tr>
<td><code>A100:2</code></td>
<td>High-Throughput VLLM</td>
<td>$6.00/hr</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="references"> References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<h3 id="design-documents">Design Documents<a class="headerlink" href="#design-documents" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Backend Architecture</strong> - Core design principles (see <code>IMPLEMENTATION_PLAN/BACKEND_ARCHITECTURE.md</code>)</li>
<li><strong>Developer Experience (DevEx)</strong> - API design and patterns (see <code>IMPLEMENTATION_PLAN/DEVEX.md</code>)</li>
<li><strong>Claude Development Guide</strong> - Implementation standards (see <code>CLAUDE.md</code> in repo root)</li>
</ul>
<h3 id="external-resources">External Resources<a class="headerlink" href="#external-resources" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://huggingface.co/Qwen/Qwen3-VL-8B-Instruct">Qwen3-VL Model Card</a></li>
<li><a href="https://huggingface.co/mlx-community/Qwen3-VL-8B-Instruct-4bit">Qwen3-VL MLX (4bit)</a></li>
<li><a href="https://modal.com/docs">Modal Documentation</a></li>
<li><a href="https://github.com/astral-sh/uv">UV Package Manager</a></li>
</ul>
<hr />
<h2 id="notes"> Notes<a class="headerlink" href="#notes" title="Permanent link">&para;</a></h2>
<h3 id="implementation-order-rationale">Implementation Order Rationale<a class="headerlink" href="#implementation-order-rationale" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Qwen3-VL Priority</strong>: Multi-backend support demonstrates v2.0 architecture</li>
<li><strong>RT-DETR</strong>: Fast fixed-label detection for production use</li>
<li><strong>Surya</strong>: Multi-language support and speed optimization</li>
<li><strong>Florence-2</strong>: Microsoft's advanced VLM capabilities</li>
</ol>
<h3 id="breaking-changes-from-v10">Breaking Changes from v1.0<a class="headerlink" href="#breaking-changes-from-v10" title="Permanent link">&para;</a></h3>
<ul>
<li>String-based factory pattern removed (use class imports)</li>
<li>Document class is now stateless (doesn't store results)</li>
<li>Config classes are model-specific (not generic)</li>
<li>Backend selection via config type (not string parameter)</li>
</ul>
<hr />
<p><strong>Last Updated</strong>: January 21, 2026
<strong>Maintainer</strong>: Adithya S Kolavi
<strong>Version</strong>: 2.0.0-dev</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="February 1, 2026 17:19:31 UTC">February 1, 2026</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="January 29, 2026 17:50:30 UTC">January 29, 2026</span>
  </span>

    
    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2025 OmniDocs. All rights reserved.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/adithya-s-k/OmniDocs" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.tabs", "navigation.sections", "navigation.top", "navigation.expand", "navigation.indexes", "search.suggest", "search.highlight", "content.code.copy", "content.code.annotate", "content.tabs.link", "content.action.edit", "content.action.view"], "search": "../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    

      <script src="../assets/javascripts/bundle.79ae519e.min.js"></script>
      
    
<script>
// Convert source code paths to GitHub links
document.addEventListener('DOMContentLoaded', function() {
  // Find all source code details elements
  const sourceDetails = document.querySelectorAll('details.quote');

  sourceDetails.forEach(function(details) {
    const summary = details.querySelector('summary');
    if (summary && summary.textContent.includes('Source code in')) {
      // Extract the file path from the summary text
      const text = summary.textContent;
      const match = text.match(/Source code in\s+(.+)/);
      if (match) {
        const filePath = match[1].trim();
        // Create GitHub link
        const githubUrl = 'https://github.com/adithya-s-k/OmniDocs/blob/main/' + filePath;

        // Create link element
        const link = document.createElement('a');
        link.href = githubUrl;
        link.target = '_blank';
        link.rel = 'noopener noreferrer';
        link.title = 'View on GitHub';
        link.style.cssText = 'margin-left: 8px; opacity: 0.7; font-size: 0.85em;';
        link.innerHTML = '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16" width="14" height="14" fill="currentColor" style="vertical-align: middle;"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path></svg>';

        summary.appendChild(link);
      }
    }
  });
});
</script>

  </body>
</html>